{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp MiDaS.MiDaS_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiDaS.MiDaS_utils\n",
    "> Default description (change me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"\"\"Utils for monoDepth.\n",
    "\"\"\"\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_pfm(path):\n",
    "    \"\"\"Read pfm file.\n",
    "\n",
    "    Args:\n",
    "        path (str): path to file\n",
    "\n",
    "    Returns:\n",
    "        tuple: (data, scale)\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as file:\n",
    "\n",
    "        color = None\n",
    "        width = None\n",
    "        height = None\n",
    "        scale = None\n",
    "        endian = None\n",
    "\n",
    "        header = file.readline().rstrip()\n",
    "        if header.decode(\"ascii\") == \"PF\":\n",
    "            color = True\n",
    "        elif header.decode(\"ascii\") == \"Pf\":\n",
    "            color = False\n",
    "        else:\n",
    "            raise Exception(\"Not a PFM file: \" + path)\n",
    "\n",
    "        dim_match = re.match(r\"^(\\d+)\\s(\\d+)\\s$\", file.readline().decode(\"ascii\"))\n",
    "        if dim_match:\n",
    "            width, height = list(map(int, dim_match.groups()))\n",
    "        else:\n",
    "            raise Exception(\"Malformed PFM header.\")\n",
    "\n",
    "        scale = float(file.readline().decode(\"ascii\").rstrip())\n",
    "        if scale < 0:\n",
    "            # little-endian\n",
    "            endian = \"<\"\n",
    "            scale = -scale\n",
    "        else:\n",
    "            # big-endian\n",
    "            endian = \">\"\n",
    "\n",
    "        data = np.fromfile(file, endian + \"f\")\n",
    "        shape = (height, width, 3) if color else (height, width)\n",
    "\n",
    "        data = np.reshape(data, shape)\n",
    "        data = np.flipud(data)\n",
    "\n",
    "        return data, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def write_pfm(path, image, scale=1):\n",
    "    \"\"\"Write pfm file.\n",
    "\n",
    "    Args:\n",
    "        path (str): pathto file\n",
    "        image (array): data\n",
    "        scale (int, optional): Scale. Defaults to 1.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path, \"wb\") as file:\n",
    "        color = None\n",
    "\n",
    "        if image.dtype.name != \"float32\":\n",
    "            raise Exception(\"Image dtype must be float32.\")\n",
    "\n",
    "        image = np.flipud(image)\n",
    "\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:  # color image\n",
    "            color = True\n",
    "        elif (\n",
    "            len(image.shape) == 2 or len(image.shape) == 3 and image.shape[2] == 1\n",
    "        ):  # greyscale\n",
    "            color = False\n",
    "        else:\n",
    "            raise Exception(\"Image must have H x W x 3, H x W x 1 or H x W dimensions.\")\n",
    "\n",
    "        file.write(\"PF\\n\" if color else \"Pf\\n\".encode())\n",
    "        file.write(\"%d %d\\n\".encode() % (image.shape[1], image.shape[0]))\n",
    "\n",
    "        endian = image.dtype.byteorder\n",
    "\n",
    "        if endian == \"<\" or endian == \"=\" and sys.byteorder == \"little\":\n",
    "            scale = -scale\n",
    "\n",
    "        file.write(\"%f\\n\".encode() % scale)\n",
    "\n",
    "        image.tofile(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_image(path):\n",
    "    \"\"\"Read image and output RGB image (0-1).\n",
    "\n",
    "    Args:\n",
    "        path (str): path to file\n",
    "\n",
    "    Returns:\n",
    "        array: RGB image (0-1)\n",
    "    \"\"\"\n",
    "    img = cv2.imread(path)\n",
    "\n",
    "    if img.ndim == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255.0\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resize_image(img):\n",
    "    \"\"\"Resize image and make it fit for network.\n",
    "\n",
    "    Args:\n",
    "        img (array): image\n",
    "\n",
    "    Returns:\n",
    "        tensor: data ready for network\n",
    "    \"\"\"\n",
    "    height_orig = img.shape[0]\n",
    "    width_orig = img.shape[1]\n",
    "    unit_scale = 384.\n",
    "\n",
    "    if width_orig > height_orig:\n",
    "        scale = width_orig / unit_scale\n",
    "    else:\n",
    "        scale = height_orig / unit_scale\n",
    "\n",
    "    height = (np.ceil(height_orig / scale / 32) * 32).astype(int)\n",
    "    width = (np.ceil(width_orig / scale / 32) * 32).astype(int)\n",
    "\n",
    "    img_resized = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    img_resized = (\n",
    "        torch.from_numpy(np.transpose(img_resized, (2, 0, 1))).contiguous().float()\n",
    "    )\n",
    "    img_resized = img_resized.unsqueeze(0)\n",
    "\n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resize_depth(depth, width, height):\n",
    "    \"\"\"Resize depth map and bring to CPU (numpy).\n",
    "\n",
    "    Args:\n",
    "        depth (tensor): depth\n",
    "        width (int): image width\n",
    "        height (int): image height\n",
    "\n",
    "    Returns:\n",
    "        array: processed depth\n",
    "    \"\"\"\n",
    "    depth = torch.squeeze(depth[0, :, :, :]).to(\"cpu\")\n",
    "    depth = cv2.blur(depth.numpy(), (3, 3))\n",
    "    depth_resized = cv2.resize(\n",
    "        depth, (width, height), interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "\n",
    "    return depth_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def write_depth(path, depth, bits=1):\n",
    "    \"\"\"Write depth map to pfm and png file.\n",
    "\n",
    "    Args:\n",
    "        path (str): filepath without extension\n",
    "        depth (array): depth\n",
    "    \"\"\"\n",
    "    # write_pfm(path + \".pfm\", depth.astype(np.float32))\n",
    "\n",
    "    depth_min = depth.min()\n",
    "    depth_max = depth.max()\n",
    "\n",
    "    max_val = (2**(8*bits))-1\n",
    "\n",
    "    if depth_max - depth_min > np.finfo(\"float\").eps:\n",
    "        out = max_val * (depth - depth_min) / (depth_max - depth_min)\n",
    "    else:\n",
    "        out = 0\n",
    "\n",
    "    if bits == 1:\n",
    "        cv2.imwrite(path + \".png\", out.astype(\"uint8\"))\n",
    "    elif bits == 2:\n",
    "        cv2.imwrite(path + \".png\", out.astype(\"uint16\"))\n",
    "        \n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
