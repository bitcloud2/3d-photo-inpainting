{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp MiDaS.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiDaS.run\n",
    "> Default description (change me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"\"\"Compute depth maps for images in the input folder.\n",
    "\"\"\"\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "# from monodepth_net import MonoDepthNet\n",
    "# import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def run_depth(img_names, input_path, output_path, model_path, Net, utils, target_w=None):\n",
    "    \"\"\"Run MonoDepthNN to compute depth maps.\n",
    "\n",
    "    Args:\n",
    "        input_path (str): path to input folder\n",
    "        output_path (str): path to output folder\n",
    "        model_path (str): path to saved model\n",
    "    \"\"\"\n",
    "    print(\"initialize\")\n",
    "\n",
    "    # select device\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"device: %s\" % device)\n",
    "\n",
    "    # load network\n",
    "    model = Net(model_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # get input\n",
    "    # img_names = glob.glob(os.path.join(input_path, \"*\"))\n",
    "    num_images = len(img_names)\n",
    "\n",
    "    # create output folder\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    print(\"start processing\")\n",
    "\n",
    "    for ind, img_name in enumerate(img_names):\n",
    "\n",
    "        print(\"  processing {} ({}/{})\".format(img_name, ind + 1, num_images))\n",
    "\n",
    "        # input\n",
    "        img = utils.read_image(img_name)\n",
    "        w = img.shape[1]\n",
    "        scale = 640. / max(img.shape[0], img.shape[1])\n",
    "        target_height, target_width = int(round(img.shape[0] * scale)), int(round(img.shape[1] * scale))\n",
    "        img_input = utils.resize_image(img)\n",
    "        print(img_input.shape)\n",
    "        img_input = img_input.to(device)\n",
    "        # compute\n",
    "        with torch.no_grad():\n",
    "            out = model.forward(img_input)\n",
    "        \n",
    "        depth = utils.resize_depth(out, target_width, target_height)\n",
    "        img = cv2.resize((img * 255).astype(np.uint8), (target_width, target_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        filename = os.path.join(\n",
    "            output_path, os.path.splitext(os.path.basename(img_name))[0]\n",
    "        )\n",
    "        np.save(filename + '.npy', depth)\n",
    "        utils.write_depth(filename, depth, bits=2)\n",
    "\n",
    "    print(\"finished\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # set paths\n",
    "#     INPUT_PATH = \"image\"\n",
    "#     OUTPUT_PATH = \"output\"\n",
    "#     MODEL_PATH = \"model.pt\"\n",
    "\n",
    "#     # set torch options\n",
    "#     torch.backends.cudnn.enabled = True\n",
    "#     torch.backends.cudnn.benchmark = True\n",
    "\n",
    "#     # compute depth maps\n",
    "#     run_depth(INPUT_PATH, OUTPUT_PATH, MODEL_PATH, Net, target_w=640)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
